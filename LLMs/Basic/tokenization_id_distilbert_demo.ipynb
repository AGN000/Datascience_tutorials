{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2690d688",
   "metadata": {},
   "source": [
    "# Tokenization → Token IDs → Embeddings (DistilBERT)\n",
    "\n",
    "This tutorial demonstrates **exactly** how an open-source LLM processes text:\n",
    "\n",
    "**Text → Tokens → Token IDs → Embeddings → Transformer**\n",
    "\n",
    "We use `distilbert-base-uncased` for clarity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb6d6f5",
   "metadata": {},
   "source": [
    "## 1. Install dependencies (run once)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3db87a6",
   "metadata": {},
   "source": [
    "## 2. Load tokenizer and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b317be37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\arung\\anaconda3\\envs\\torch_clean\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DistilBertModel(\n",
       "  (embeddings): Embeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (transformer): Transformer(\n",
       "    (layer): ModuleList(\n",
       "      (0-5): 6 x TransformerBlock(\n",
       "        (attention): DistilBertSdpaAttention(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (ffn): FFN(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (activation): GELUActivation()\n",
       "        )\n",
       "        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "model_name = 'distilbert-base-uncased'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170815ec",
   "metadata": {},
   "source": [
    "## 3. Example sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cad53a87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Turbulence modeling is hard'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = 'Turbulence modeling is hard'\n",
    "sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71e7447",
   "metadata": {},
   "source": [
    "## 4. Tokenization (text → tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e88f3120",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['turbulence', 'modeling', 'is', 'hard']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = tokenizer.tokenize(sentence)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d559d3f1",
   "metadata": {},
   "source": [
    "## 5. Token IDs (tokens → numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09a3e780",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[29083, 11643, 2003, 2524]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "token_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29357acd",
   "metadata": {},
   "source": [
    "## 6. Full tokenizer output (what the model really sees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00da1c54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101, 29083, 11643,  2003,  2524,   102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded = tokenizer(sentence, return_tensors='pt')\n",
    "encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18337405",
   "metadata": {},
   "source": [
    "## 7. Embedding + Transformer output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "564f5a59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 6, 768])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(**encoded)\n",
    "\n",
    "last_hidden_state = outputs.last_hidden_state\n",
    "last_hidden_state.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e08e690",
   "metadata": {},
   "source": [
    "## 8. Inspect embedding for a token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "39fafed3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([768])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Token index 1 corresponds to 'turbulence'\n",
    "turbulence_embedding = last_hidden_state[0, 1]\n",
    "turbulence_embedding.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ae6700",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "- The model **never sees text or words**\n",
    "- It only sees **token IDs (integers)**\n",
    "- Token IDs index rows of an **embedding matrix**\n",
    "- After embedding lookup, **only vectors exist**\n",
    "\n",
    "**Tokenization is a compiler front-end for neural networks.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_clean",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
