{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49c251c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Subset\n",
    "import numpy as np\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST(\n",
    "    root=\"./data\", train=True, download=True, transform=transform\n",
    ")\n",
    "\n",
    "targets = train_dataset.targets.numpy()\n",
    "indices = []\n",
    "\n",
    "imbalance_ratio = {\n",
    "    8: 0.1,   # 10% of samples\n",
    "    9: 0.01   # 1% of samples\n",
    "}\n",
    "\n",
    "for digit in range(10):\n",
    "    digit_indices = np.where(targets == digit)[0]\n",
    "    if digit in imbalance_ratio:\n",
    "        n_keep = int(len(digit_indices) * imbalance_ratio[digit])\n",
    "        digit_indices = np.random.choice(digit_indices, n_keep, replace=False)\n",
    "    indices.extend(digit_indices)\n",
    "\n",
    "imbalanced_train_dataset = Subset(train_dataset, indices)\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "labels = train_dataset.targets[indices].numpy()\n",
    "unique, counts = np.unique(labels, return_counts=True)\n",
    "\n",
    "plt.bar(unique, counts)\n",
    "plt.xlabel(\"Digit\")\n",
    "plt.ylabel(\"Number of samples\")\n",
    "plt.title(\"Class distribution (Imbalanced MNIST)\")\n",
    "plt.show()\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        return self.fc2(x)\n",
    "\n",
    "\n",
    "def per_class_accuracy(model, dataloader, device):\n",
    "    correct = torch.zeros(10)\n",
    "    total = torch.zeros(10)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x, y in dataloader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            preds = model(x).argmax(dim=1)\n",
    "\n",
    "            for i in range(10):\n",
    "                mask = (y == i)\n",
    "                correct[i] += (preds[mask] == i).sum().item()\n",
    "                total[i] += mask.sum().item()\n",
    "\n",
    "    return (correct / total).cpu().numpy()\n",
    "\n",
    "acc = per_class_accuracy(model, test_loader, device)\n",
    "\n",
    "plt.bar(range(10), acc)\n",
    "plt.xlabel(\"Digit\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Per-class accuracy on imbalanced MNIST\")\n",
    "plt.ylim(0, 1)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
