{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e77581f",
   "metadata": {},
   "source": [
    "# Attention and Multi-Head Attention — Formulas + Numerical Example\n",
    "\n",
    "This notebook explains **self-attention** and **multi-head attention** step by step.\n",
    "\n",
    "Contents:\n",
    "1. Definitions of Q, K, V\n",
    "2. Attention formulas\n",
    "3. Simple (single-head) self-attention — numerical example\n",
    "4. Multi-head attention — numerical example\n",
    "\n",
    "Example sentence:\n",
    "```\n",
    "I love machine learning\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c381da2",
   "metadata": {},
   "source": [
    "## 1. What are Q, K, V?\n",
    "\n",
    "We start with a sequence of token embeddings:\n",
    "\n",
    "$X = [x_1, x_2, \\dots, x_N], \\quad x_i \\in \\mathbb{R}^{d_{model}}$\n",
    "Each token is projected into three different vectors:\n",
    "\n",
    "$Q = XW_Q,\\quad K = XW_K,\\quad V = XW_V$\n",
    "Where:\n",
    "- $W_Q, W_K, W_V \\in \\mathbb{R}^{d_{model} \\times d_k}$ are learned matrices\n",
    "- $Q, K, V \\in \\mathbb{R}^{N \\times d_k}$\n",
    "\n",
    "**Q** is used to compute relevance,\n",
    "\n",
    "**K** provides matching information,\n",
    "\n",
    "**V** contains the information that will be mixed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4ccd5e",
   "metadata": {},
   "source": [
    "## 2. Self-Attention Formula\n",
    "\n",
    "Step 1: Similarity scores\n",
    "\n",
    "$S = QK^T$\n",
    "\n",
    "Step 2: Scaling\n",
    "\n",
    "$\\hat{S} = \\frac{QK^T}{\\sqrt{d_k}}$\n",
    "Step 3: Softmax (row-wise)\n",
    "\n",
    "$A = \\text{softmax}(\\hat{S})$\n",
    "Step 4: Output\n",
    "\n",
    "$\\boxed{\\text{Attention}(Q,K,V) = AV}$\n",
    "Output shape: \n",
    "$\\mathbb{R}^{N \\times d_k}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c16293",
   "metadata": {},
   "source": [
    "## 3. Input embeddings (numerical example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cfa05f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import math\n",
    "\n",
    "X = torch.tensor([\n",
    "    [1., 0., 1., 0.],   # I\n",
    "    [0., 1., 1., 0.],   # love\n",
    "    [1., 1., 0., 1.],   # machine\n",
    "    [0., 1., 0., 1.]    # learning\n",
    "])\n",
    "\n",
    "X\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1721d39f",
   "metadata": {},
   "source": [
    "## 4. Simple (Single-Head) Self-Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937f9225",
   "metadata": {},
   "source": [
    "For clarity, we use identity matrices for $W_Q, W_K, W_V$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ce0235",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "d_model = X.shape[1]\n",
    "\n",
    "WQ = torch.eye(d_model)\n",
    "WK = torch.eye(d_model)\n",
    "WV = torch.eye(d_model)\n",
    "\n",
    "Q = X @ WQ\n",
    "K = X @ WK\n",
    "V = X @ WV\n",
    "\n",
    "d_k = Q.shape[1]\n",
    "\n",
    "scores = Q @ K.T / math.sqrt(d_k)\n",
    "weights = torch.softmax(scores, dim=1)\n",
    "output_single = weights @ V\n",
    "\n",
    "scores, weights, output_single\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1236ff24",
   "metadata": {},
   "source": [
    "## 5. Multi-Head Attention Formula\n",
    "\n",
    "For $h$ heads:\n",
    "\n",
    "$Q^{(i)} = XW_Q^{(i)},\\quad K^{(i)} = XW_K^{(i)},\\quad V^{(i)} = XW_V^{(i)}$\n",
    "$O^{(i)} = \\text{Attention}(Q^{(i)}, K^{(i)}, V^{(i)})$\n",
    "\n",
    "\n",
    "Concatenate outputs:\n",
    "\n",
    "$O = \\text{Concat}(O^{(1)}, \\dots, O^{(h)})$\n",
    "\n",
    "Final projection:\n",
    "\n",
    "$\\boxed{\\text{MHA}(X) = OW_O}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52abb1a0",
   "metadata": {},
   "source": [
    "## 6. Multi-Head Attention (2 heads, numerical)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89dc642f",
   "metadata": {},
   "source": [
    "- Number of heads = 2\n",
    "- Head dimension = 2\n",
    "- Total dimension = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f587e3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Projection matrices for two heads\n",
    "\n",
    "# Head 1 -> first two features\n",
    "WQ1 = WK1 = WV1 = torch.tensor([\n",
    "    [1., 0.],\n",
    "    [0., 1.],\n",
    "    [0., 0.],\n",
    "    [0., 0.]\n",
    "])\n",
    "\n",
    "# Head 2 -> last two features\n",
    "WQ2 = WK2 = WV2 = torch.tensor([\n",
    "    [0., 0.],\n",
    "    [0., 0.],\n",
    "    [1., 0.],\n",
    "    [0., 1.]\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ffe615",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def attention(Q, K, V):\n",
    "    d_k = Q.shape[1]\n",
    "    scores = Q @ K.T / math.sqrt(d_k)\n",
    "    weights = torch.softmax(scores, dim=1)\n",
    "    return weights @ V, weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c985c70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Head 1\n",
    "Q1, K1, V1 = X @ WQ1, X @ WK1, X @ WV1\n",
    "O1, A1 = attention(Q1, K1, V1)\n",
    "\n",
    "# Head 2\n",
    "Q2, K2, V2 = X @ WQ2, X @ WK2, X @ WV2\n",
    "O2, A2 = attention(Q2, K2, V2)\n",
    "\n",
    "O1, A1, O2, A2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516172f9",
   "metadata": {},
   "source": [
    "## 7. Concatenate heads and output projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f89e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "O = torch.cat([O1, O2], dim=1)\n",
    "\n",
    "# Identity output projection for clarity\n",
    "WO = torch.eye(4)\n",
    "Y = O @ WO\n",
    "\n",
    "Y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15aad52",
   "metadata": {},
   "source": [
    "## Summary\n",
    "- Q, K, V are linear projections of the same input\n",
    "- Self-attention computes a weighted sum of values\n",
    "- Multi-head attention repeats this in parallel subspaces\n",
    "- Outputs are concatenated and projected"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
