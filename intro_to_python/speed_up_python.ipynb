{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "629d94ed",
   "metadata": {},
   "source": [
    "# Speed Up Phython #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334a7d2e",
   "metadata": {},
   "source": [
    "## Python Loop vs List Comprehension ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086bf49a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slow loop time: 13.22475814819336 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "def slow_square(nums):\n",
    "    result = []\n",
    "    for n in nums:\n",
    "        result.append(n*n)\n",
    "    return result\n",
    "\n",
    "# Timing\n",
    "nums = list(range(1_000_0000))\n",
    "\n",
    "start = time.time()\n",
    "slow_square(nums)\n",
    "end = time.time()\n",
    "total_time1 = end - start\n",
    "print(\"Slow loop time:\", end - start, \"seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c5b9be",
   "metadata": {},
   "source": [
    "### Optimized Version: List Comprehension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d132cd7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List comprehension time: 6.795704126358032 seconds\n",
      "Speedup percentage: 48.61377387618694\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "def fast_square(nums):\n",
    "    return [n*n for n in nums]\n",
    "\n",
    "# Timing\n",
    "start = time.time()\n",
    "fast_square(nums)\n",
    "end = time.time()\n",
    "total_time2 = end - start\n",
    "print(\"List comprehension time:\", end - start, \"seconds\")\n",
    "\n",
    "print(\"Speedup percentage:\", (total_time1-total_time2) *100/ total_time1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630ac355",
   "metadata": {},
   "source": [
    "### Pure Python vs NumPy Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ac77ebbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arung\\AppData\\Local\\Temp\\ipykernel_16768\\1611041986.py:10: RuntimeWarning: overflow encountered in long_scalars\n",
      "  out.append(x * x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pure Python: 8.030144453048706 sec\n",
      "NumPy vectorized: 0.011869668960571289 sec\n",
      "Speedup percentage: 99.85218610910461\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "\n",
    "nums = np.arange(1_000_0000)\n",
    "\n",
    "# -------- SLOW --------\n",
    "def slow_square(nums):\n",
    "    out = []\n",
    "    for x in nums:\n",
    "        out.append(x * x)\n",
    "    return out\n",
    "\n",
    "start = time.time()\n",
    "slow_square(nums)\n",
    "t1=time.time() - start\n",
    "print(\"Pure Python:\", time.time() - start, \"sec\")\n",
    "\n",
    "# -------- FAST (NumPy) --------\n",
    "start = time.time()\n",
    "nums * nums\n",
    "t2=time.time() - start\n",
    "print(\"NumPy vectorized:\", time.time() - start, \"sec\")\n",
    "print(\"Speedup percentage:\", (t1 - t2) * 100 / t1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d2c849",
   "metadata": {},
   "source": [
    "### Using map() vs traditional loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5b197116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop: 2.0451040267944336\n",
      "map(): 0.7907052040100098\n",
      "Speedup percentage: 61.33667560914306\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "nums = list(range(1_000_0000))\n",
    "\n",
    "# SLOW\n",
    "start = time.time()\n",
    "out1 = []\n",
    "for x in nums:\n",
    "    out1.append(x + 5)\n",
    "print(\"Loop:\", time.time() - start)\n",
    "t1=time.time() - start\n",
    "# FAST\n",
    "start = time.time()\n",
    "list(map(lambda x: x + 5, nums))\n",
    "t2=time.time() - start\n",
    "print(\"map():\", time.time() - start)\n",
    "print(\"Speedup percentage:\", (t1 - t2) * 100 / t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93e8084",
   "metadata": {},
   "source": [
    "### Caching Results (functools.lru_cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aeb0f5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slow fib: 30.153449296951294\n",
      "Fast fib (cached): 0.0\n",
      "Speedup percentage: 100.0\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from functools import lru_cache\n",
    "n1=40\n",
    "# Expensive Fibonacci\n",
    "def fib_slow(n):\n",
    "    if n < 2:\n",
    "        return n\n",
    "    return fib_slow(n-1) + fib_slow(n-2)\n",
    "\n",
    "start = time.time()\n",
    "fib_slow(n1)  # slow recursive\n",
    "t1=time.time() - start\n",
    "print(\"Slow fib:\", time.time() - start)\n",
    "\n",
    "# FAST (cached)\n",
    "@lru_cache(None)\n",
    "def fib_fast(n):\n",
    "    if n < 2:\n",
    "        return n\n",
    "    return fib_fast(n-1) + fib_fast(n-2)\n",
    "\n",
    "start = time.time()\n",
    "fib_fast(n1)\n",
    "t2=time.time() - start\n",
    "print(\"Fast fib (cached):\", time.time() - start)\n",
    "print(\"Speedup percentage:\", (t1 - t2) * 100 / t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73612264",
   "metadata": {},
   "source": [
    "### Loop optimization using local variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5532bf27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global lookup: 0.8975656032562256\n",
      "Local variable bind: 0.7576634883880615\n",
      "Speedup percentage: 15.586840043849875\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "nums = list(range(1_000_0000))\n",
    "\n",
    "# SLOW: global lookup inside loop\n",
    "def slow_global():\n",
    "    out = []\n",
    "    for x in nums:\n",
    "        out.append(x * 3)\n",
    "    return out\n",
    "\n",
    "# FAST: copy functions/vars into local scope\n",
    "def fast_local():\n",
    "    out = []\n",
    "    append = out.append     # local binding\n",
    "    for x in nums:\n",
    "        append(x * 3)\n",
    "    return out\n",
    "\n",
    "start = time.time()\n",
    "slow_global()\n",
    "t1= time.time() - start\n",
    "print(\"Global lookup:\", time.time() - start)\n",
    "\n",
    "start = time.time()\n",
    "fast_local()\n",
    "t2= time.time() - start\n",
    "print(\"Local variable bind:\", time.time() - start)\n",
    "print(\"Speedup percentage:\", (t1 - t2) * 100 / t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b43022f",
   "metadata": {},
   "source": [
    "### Generator vs List (Memory + Speed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e4f2168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List: 0.6271848678588867\n",
      "Generator: 0.5285592079162598\n",
      "Speedup percentage: 15.725133847587854\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "n1=10_000_000\n",
    "# SLOW: List (builds full memory)\n",
    "start = time.time()\n",
    "sum([i for i in range(n1)])\n",
    "print(\"List:\", time.time() - start)\n",
    "t1=time.time() - start\n",
    "# FAST: generator (streaming)\n",
    "start = time.time()\n",
    "sum(i for i in range(n1))\n",
    "print(\"Generator:\", time.time() - start)\n",
    "t2=time.time() - start\n",
    "print(\"Speedup percentage:\", (t1 - t2) * 100 / t1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d477b2",
   "metadata": {},
   "source": [
    "### Multiprocessing for CPU-heavy tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe1d07a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected CPU cores (processes to use): 12\n",
      "Preparing data: Generating large matrices...\n",
      "\n",
      "--- Single Process Results ---\n",
      "Matrix size: 3000x3000\n",
      "Time Taken: 0.3543 seconds\n"
     ]
    }
   ],
   "source": [
    "# import time\n",
    "# import numpy as np\n",
    "# from multiprocessing import Pool, cpu_count\n",
    "\n",
    "# # --- Configuration ---\n",
    "# # Choose a matrix size that makes the calculation long enough (e.g., 500x500)\n",
    "# MATRIX_SIZE = 3000\n",
    "# # Use all available CPU cores for maximum speed-up demonstration\n",
    "# NUM_PROCESSES = cpu_count()\n",
    "# print(f\"Detected CPU cores (processes to use): {NUM_PROCESSES}\")\n",
    "\n",
    "# # --- The Computation Function ---\n",
    "# def multiply_matrices(chunk):\n",
    "#     \"\"\"\n",
    "#     Function to be executed by each process.\n",
    "#     It takes a chunk of rows from matrix A and multiplies it \n",
    "#     by the entire matrix B.\n",
    "#     \"\"\"\n",
    "#     A_chunk, B = chunk\n",
    "#     # NumPy's matmul (@) is highly optimized for this\n",
    "#     return A_chunk @ B\n",
    "\n",
    "# # --- Main Execution Block ---\n",
    "# if __name__ == \"__main__\":\n",
    "#     # 1. Data Preparation (NumPy matrices are efficient)\n",
    "#     print(\"Preparing data: Generating large matrices...\")\n",
    "#     A = np.random.rand(MATRIX_SIZE, MATRIX_SIZE)\n",
    "#     B = np.random.rand(MATRIX_SIZE, MATRIX_SIZE)\n",
    "    \n",
    "#     # Calculate the number of rows each process should handle\n",
    "#     rows_per_process = MATRIX_SIZE // NUM_PROCESSES\n",
    "    \n",
    "#     # Split Matrix A into chunks (rows)\n",
    "#     chunks = []\n",
    "#     for i in range(NUM_PROCESSES):\n",
    "#         start_row = i * rows_per_process\n",
    "#         # Handle the remainder in the last chunk\n",
    "#         end_row = (i + 1) * rows_per_process if i < NUM_PROCESSES - 1 else MATRIX_SIZE\n",
    "        \n",
    "#         # Each item in the iterable must be the input for the worker function\n",
    "#         # We pass the relevant rows of A and the whole matrix B\n",
    "#         chunks.append((A[start_row:end_row, :], B))\n",
    "\n",
    "#     # --- 2. Single-Process Execution (Baseline) ---\n",
    "#     start_single = time.perf_counter()\n",
    "#     # The multiplication is done directly in the main process\n",
    "#     C_single = A @ B\n",
    "#     end_single = time.perf_counter()\n",
    "#     single_time = end_single - start_single\n",
    "    \n",
    "#     print(\"\\n--- Single Process Results ---\")\n",
    "#     print(f\"Matrix size: {MATRIX_SIZE}x{MATRIX_SIZE}\")\n",
    "#     print(f\"Time Taken: {single_time:.4f} seconds\")\n",
    "\n",
    "#     # --- 3. Multi-Process Execution ---\n",
    "#     start_multi = time.perf_counter()\n",
    "    \n",
    "#     # Use the Pool of worker processes\n",
    "#     with Pool(processes=NUM_PROCESSES) as pool:\n",
    "#         # map() distributes the chunks iterable to the workers\n",
    "#         partial_results = pool.map(multiply_matrices, chunks)\n",
    "        \n",
    "#     # Reconstruct the final result matrix from the partial results\n",
    "#     C_multi = np.concatenate(partial_results, axis=0)\n",
    "    \n",
    "#     end_multi = time.perf_counter()\n",
    "#     multi_time = end_multi - start_multi\n",
    "    \n",
    "#     print(\"\\n--- Multi Process Results ---\")\n",
    "#     print(f\"Time Taken: {multi_time:.4f} seconds (using {NUM_PROCESSES} processes)\")\n",
    "    \n",
    "#     # --- 4. Validation and Summary ---\n",
    "#     # Check if the results are numerically close\n",
    "#     is_correct = np.allclose(C_single, C_multi)\n",
    "    \n",
    "#     speed_up = single_time / multi_time\n",
    "    \n",
    "#     print(f\"\\nResult Validation: {'Passed' if is_correct else 'Failed'}\")\n",
    "#     print(\"--- Summary ---\")\n",
    "#     print(f\"Speed-up Factor: **{speed_up:.2f}x**\")\n",
    "#     print(f\"This demonstrates parallel processing overcoming the Python GIL on a CPU-bound task.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8df60f",
   "metadata": {},
   "source": [
    "### Numba JIT Compilation (Massive Speedup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e4a4b82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.217660427093506\n",
      "Numba JIT: 0.0\n",
      "Speedup percentage: 100.0\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from numba import njit\n",
    "\n",
    "# SLOW pure python\n",
    "def slow_compute(n):\n",
    "    s = 0\n",
    "    for i in range(n):\n",
    "        s += i * 2\n",
    "    return s\n",
    "\n",
    "start = time.time()\n",
    "slow_compute(50_000_000)\n",
    "print(\"Python:\", time.time() - start)\n",
    "t1=time.time() - start\n",
    "# FAST with JIT\n",
    "@njit\n",
    "def fast_compute(n):\n",
    "    s = 0\n",
    "    for i in range(n):\n",
    "        s += i * 2\n",
    "    return s\n",
    "\n",
    "# First call compiles (slow)\n",
    "fast_compute(1)\n",
    "\n",
    "start = time.time()\n",
    "fast_compute(50_000_000)\n",
    "print(\"Numba JIT:\", time.time() - start)\n",
    "t2=time.time() - start\n",
    "print(\"Speedup percentage:\", (t1 - t2) * 100 / t1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f6d15e",
   "metadata": {},
   "source": [
    "### Using sets for O(1) lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "581fc84d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List lookup: 0.08551478385925293\n",
      "Set lookup: 0.0009996891021728516\n",
      "Speedup percentage: 98.83097511674914\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "items = list(range(1_000_0000))\n",
    "lookup = 999_99999\n",
    "\n",
    "# SLOW: list search O(n)\n",
    "start = time.time()\n",
    "found = lookup in items\n",
    "print(\"List lookup:\", time.time() - start)\n",
    "t1=time.time() - start\n",
    "# FAST: set search O(1)\n",
    "s = set(items)\n",
    "start = time.time()\n",
    "found = lookup in s\n",
    "print(\"Set lookup:\", time.time() - start)\n",
    "t2=time.time() - start\n",
    "print(\"Speedup percentage:\", (t1 - t2) * 100 / t1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878f4738",
   "metadata": {},
   "source": [
    "### Using join() instead of + for strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a53d714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "String + concat: 0.14478397369384766\n",
      "join(): 0.002000093460083008\n",
      "Speedup percentage: 98.61856709064202\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "words = [\"hello\"] * 300000\n",
    "\n",
    "# SLOW\n",
    "start = time.time()\n",
    "s = \"\"\n",
    "for w in words:\n",
    "    s += w  # string concatenation (expensive!)\n",
    "print(\"String + concat:\", time.time() - start)\n",
    "t1=time.time() - start\n",
    "# FAST\n",
    "start = time.time()\n",
    "\"\".join(words)\n",
    "print(\"join():\", time.time() - start)\n",
    "t2=time.time() - start\n",
    "print(\"Speedup percentage:\", (t1 - t2) * 100 / t1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
